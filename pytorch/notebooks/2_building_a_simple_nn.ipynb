{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ca28a8-998f-451d-8960-c6aeeaaddd6c",
   "metadata": {},
   "source": [
    "# Building simple NN with pytorch\n",
    "\n",
    "A linear regression fit: \n",
    "\n",
    "$y = w_1 * x_1 + w_2 * x_2 + b$\n",
    "\n",
    "$Y = X \\vec w + b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4633a39-1161-421b-97dc-165a4ff5d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "# from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3557713-c929-4115-8d91-1a396a4c0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_data(w, b, num_examples):\n",
    "    \"\"\"Generate y = Xw + b + noise\"\"\"\n",
    "    # draw from normal distribution\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    # make use of broadcasting here\n",
    "    y = torch.matmul(X, w) + b\n",
    "    # add some noise\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Construct a Pytorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2a8cd0-8f99-4243-a864-adf0760b43a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 2]), torch.Size([1000, 1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_w = torch.tensor([2, 3.4])\n",
    "true_b = 4.2\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee368aa5-9a67-4d1a-8194-e822a1faebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25dbd948-b0d6-4778-8f43-e2d5645a2358",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.7426, -1.8236],\n",
       "         [-0.0831, -1.6884],\n",
       "         [ 0.6476, -0.1389],\n",
       "         [-0.0250, -0.4641],\n",
       "         [-1.1752,  0.1984],\n",
       "         [-1.6225, -1.8055],\n",
       "         [-0.8927,  0.5474],\n",
       "         [ 0.4309,  1.1383],\n",
       "         [ 1.5729, -0.3027],\n",
       "         [ 0.8980, -0.3180]]),\n",
       " tensor([[ 1.4806],\n",
       "         [-1.6905],\n",
       "         [ 5.0158],\n",
       "         [ 2.5794],\n",
       "         [ 2.5536],\n",
       "         [-5.1871],\n",
       "         [ 4.2896],\n",
       "         [ 8.9372],\n",
       "         [ 6.3109],\n",
       "         [ 4.9221]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity test\n",
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f42bb1d-4420-4e58-b58a-ea99a6fe7ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the fully-connected layer is defined in the Linear class\n",
    "model = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7c1b85-3891-46bc-bda3-57cd47f838c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize w1, w2, and b\n",
    "model[0].weight.data.normal_(0, 0.01)\n",
    "model[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14dba99e-9559-4a5f-a3e8-38f6a135addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the cost function and optmizer\n",
    "loss = nn.MSELoss()  # squared L2 norm\n",
    "trainer = torch.optim.SGD(model.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b553a69a-b26a-4c2e-955f-d4d8b325505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000196\n",
      "epoch 2, loss 0.000102\n",
      "epoch 3, loss 0.000102\n"
     ]
    }
   ],
   "source": [
    "# the most simplistic training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        l_estimation = loss(model(X), y)\n",
    "        trainer.zero_grad()  # reset the gradients\n",
    "        l_estimation.backward()  # find the new gradients based on the current loss\n",
    "        trainer.step()  # update the parameters\n",
    "\n",
    "    l_estimation = loss(model(features), labels)\n",
    "    print(f\"epoch {epoch + 1}, loss {l_estimation:f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3a11c8-73c7-4dfb-9166-151189188bce",
   "metadata": {},
   "source": [
    "## Logistic/Softmax regression and cross entropy loos\n",
    "\n",
    "The logistic function:\n",
    "$\\displaystyle f(x)= \\sigma(x) = {\\frac {1}{1+e^{-x}}}$\n",
    "\n",
    "The softmax function:\n",
    "\n",
    "\n",
    "The cross entropy function: \n",
    "${\\displaystyle H(p,q)=-\\sum _{x\\in {\\mathcal {X}}}p(x)\\,\\log q(x)}{\\displaystyle H(p,q)=-\\sum _{x\\in {\\mathcal {X}}}p(x)\\,\\log q(x)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cbae3fc-8744-42ad-bff6-9ad36b2c7a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \"\"\"Donwload the Fashion-MNIST dataset and load it into memory\"\"\"\n",
    "    transformations = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        transformations.insert(0, transforms.Resize(resize))\n",
    "\n",
    "    transformations = transforms.Compose(transformations)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=True, transform=transformations, download=True\n",
    "    )\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=\"../data\", train=False, transform=transformations, download=True\n",
    "    )\n",
    "    return (\n",
    "        data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=2),\n",
    "        data.DataLoader(mnist_test, batch_size, shuffle=False, num_workers=2),\n",
    "    )\n",
    "\n",
    "\n",
    "def initialize_weights_randomly(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.normal_(layer.weight, std=0.01)\n",
    "\n",
    "\n",
    "def init_normal(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(layer.bias)\n",
    "\n",
    "\n",
    "def accuracy(y_hat, y):\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "\n",
    "\n",
    "def train_loop(net, data_iter, trainer, loss_function, num_epochs=3):\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in data_iter:\n",
    "            y_hat = net(X)\n",
    "            l_estimation = loss_function(y_hat, y)\n",
    "            trainer.zero_grad()  # reset the gradients\n",
    "            l_estimation.backward()  # find the new partial derivatives & gradients based on the current loss\n",
    "            trainer.step()  # update the parameters with 1 iteration of Gradient Descent\n",
    "\n",
    "        acc = accuracy(net(X), y)\n",
    "        print(f\"epoch {epoch + 1}, accuracy {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19604021-5454-4b75-ab86-69925bea816c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))\n",
    "model.apply(initialize_weights_randomly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e61cc981-3c14-4b67-ab73-d873136da321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ../data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "3.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ../data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=100)\n",
    "# for X, y in train_iter:\n",
    "#     print(X.shape, y.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb14c95c-5887-4a78-a873-a81d9339af1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, accuracy 84.00\n",
      "epoch 2, accuracy 82.00\n",
      "epoch 3, accuracy 83.00\n",
      "epoch 4, accuracy 85.00\n",
      "epoch 5, accuracy 91.00\n",
      "epoch 6, accuracy 84.00\n",
      "epoch 7, accuracy 90.00\n",
      "epoch 8, accuracy 88.00\n",
      "epoch 9, accuracy 89.00\n",
      "epoch 10, accuracy 85.00\n"
     ]
    }
   ],
   "source": [
    "train_loop(\n",
    "    model,\n",
    "    data_iter=train_iter,\n",
    "    trainer=torch.optim.SGD(model.parameters(), lr=0.1),\n",
    "    loss_function=nn.CrossEntropyLoss(),\n",
    "    num_epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe005a98-733d-4db8-a93d-b8a7bab320d8",
   "metadata": {},
   "source": [
    "### Inspecting the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5ed6282-120e-4cd8-8779-c84a57f891d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('1.weight',\n",
       "              tensor([[ 0.0008,  0.0025, -0.0004,  ..., -0.0317, -0.0184, -0.0082],\n",
       "                      [-0.0033, -0.0025, -0.0019,  ..., -0.0153,  0.0078, -0.0076],\n",
       "                      [ 0.0119,  0.0011, -0.0039,  ...,  0.0806,  0.0449,  0.0015],\n",
       "                      ...,\n",
       "                      [ 0.0245, -0.0116,  0.0023,  ..., -0.0103, -0.0027, -0.0094],\n",
       "                      [ 0.0072, -0.0151, -0.0237,  ..., -0.0823, -0.0302, -0.0224],\n",
       "                      [-0.0005,  0.0022, -0.0029,  ..., -0.0169,  0.0070,  0.0028]])),\n",
       "             ('1.bias',\n",
       "              tensor([ 0.5171, -0.6317, -0.0854,  0.4342, -1.4327,  2.6480,  0.5326,  0.0185,\n",
       "                      -0.5418, -1.4618]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e4b2e18-415f-42b9-ab2e-6f876174397c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 0.0008,  0.0025, -0.0004,  ..., -0.0317, -0.0184, -0.0082],\n",
       "                      [-0.0033, -0.0025, -0.0019,  ..., -0.0153,  0.0078, -0.0076],\n",
       "                      [ 0.0119,  0.0011, -0.0039,  ...,  0.0806,  0.0449,  0.0015],\n",
       "                      ...,\n",
       "                      [ 0.0245, -0.0116,  0.0023,  ..., -0.0103, -0.0027, -0.0094],\n",
       "                      [ 0.0072, -0.0151, -0.0237,  ..., -0.0823, -0.0302, -0.0224],\n",
       "                      [-0.0005,  0.0022, -0.0029,  ..., -0.0169,  0.0070,  0.0028]])),\n",
       "             ('bias',\n",
       "              tensor([ 0.5171, -0.6317, -0.0854,  0.4342, -1.4327,  2.6480,  0.5326,  0.0185,\n",
       "                      -0.5418, -1.4618]))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5624d37a-cf4c-40aa-a097-a2bca4f41a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.weight\n",
      "1.bias\n"
     ]
    }
   ],
   "source": [
    "for n, _ in model.named_parameters():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b196dda1-8851-4b13-ae1a-ac34ed196578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125f77e-dd1e-4bfb-93b0-7f382346dadb",
   "metadata": {},
   "source": [
    "#### Looking into nested architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d24ccfd2-63ba-4a57-bc27-3b8df2fb96c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(4, 8), nn.ReLU())\n",
    "\n",
    "\n",
    "def block2(size: int = 2):\n",
    "    net = nn.Sequential()\n",
    "    for i in range(size):\n",
    "        net.add_module(f\"inner block {i}\", block1())\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fb10c3a-e8f8-49ae-a3dc-78f078eaa2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_net = nn.Sequential(block2(), nn.Linear(4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35ad21f9-1f27-4e00-9c7f-19da09caf296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (inner block 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (inner block 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(nested_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1400fbbe-b80b-4ecb-ae59-de8e10ad07d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4445,  0.1798,  0.1653,  0.1982],\n",
       "        [-0.0170,  0.0357,  0.1242,  0.2522],\n",
       "        [ 0.2361,  0.0823, -0.3425, -0.2136],\n",
       "        [-0.0222, -0.0907,  0.3527, -0.1307],\n",
       "        [ 0.3407, -0.1102, -0.2743, -0.2541],\n",
       "        [ 0.2337,  0.3699,  0.2471, -0.1450],\n",
       "        [-0.3615,  0.1531, -0.3844, -0.3738],\n",
       "        [-0.3422, -0.2349,  0.3745,  0.3075]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing a specific layer. The first Linear inside the \"inner block 0\":\n",
    "nested_net[0][1][0].weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d4aca-f186-4bf0-b329-4007ade1f34a",
   "metadata": {},
   "source": [
    "## Load and save parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13bbbb8c-e50f-4d6f-bad9-5c86ca8e5456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        flatted = self.flatten(x)\n",
    "        return self.linear_relu_stack(flatted)  # logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dd48ba9-efb5-4b82-ae92-ce93c277efc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8bd6fe1-709e-4273-9e35-ea43c3c62892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0402,  0.0196,  0.0289, -0.1012,  0.1121,  0.2018,  0.1489, -0.1140,\n",
      "          0.0565, -0.0296]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(size=(1, 28, 28))\n",
    "logits = model(X)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4d01f75-63d5-48c1-ae10-ab99cb9bf7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0999, 0.0979, 0.0988, 0.0867, 0.1074, 0.1175, 0.1114, 0.0856, 0.1016,\n",
      "         0.0932]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "# Now we applies the Softmax function to the logits Tensor\n",
    "# rescaling them so that the elements lie in the range [0,1] and sum to 1.\n",
    "pred_probabilities = nn.Softmax(dim=1)(logits)\n",
    "print(pred_probabilities)\n",
    "print(torch.argmax(pred_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b333b278-f443-476a-8ac8-1c0b9a4bd950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "torch.save(model.state_dict(), \"mlp.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d05fea3-5acc-49fb-8637-350af3b324fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading\n",
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load(\"mlp.params\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54817924-5013-49d6-b716-53fea5176b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
