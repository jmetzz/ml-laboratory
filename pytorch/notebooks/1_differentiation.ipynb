{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862766cc-13c6-4310-b7b8-d61877c31fee",
   "metadata": {},
   "source": [
    "## Differentiation\n",
    "\n",
    "`torch.autograd` the pytorch automatic differentiation engine.\n",
    "\n",
    "Derivative is the instantaneous rate of range.\n",
    "\n",
    "Partial derivatives: the gradient of $f(x_1, ..., x_n)$ is a vector of $n$ partial derivatives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d598032c-5799-4431-b01c-6d7895309720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed70daf-70e3-44b3-8021-dce7ad82f013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h=0.100000, numerical limit=2.300000\n",
      "h=0.010000, numerical limit=2.030000\n",
      "h=0.001000, numerical limit=2.003000\n",
      "h=0.000100, numerical limit=2.000300\n",
      "h=0.000010, numerical limit=2.000030\n",
      "h=0.000001, numerical limit=2.000003\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return 3 * x**2 - 4 * x\n",
    "\n",
    "\n",
    "def numerical_lim(f, x, h):\n",
    "    return (f(x + h) - f(x)) / h\n",
    "\n",
    "\n",
    "h = 0.1\n",
    "for _ in range(6):\n",
    "    print(f\"h={h:.6f}, numerical limit={numerical_lim(f, 1, h):.6f}\")\n",
    "    h *= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96546205-c1ce-495c-bb66-0da2bc935859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4.0, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b095451-f532-49e9-832d-0e25b5a589d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)  # default is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de1604a-145a-4750-9c30-cd74793c2f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14., grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define f(x):\n",
    "y = torch.dot(x, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2951eef1-7a1f-4871-8bd3-3a60b45943fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the grandients we need to find the partial derivatives:\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc9dab7b-f3bf-4e38-b21a-cf277ab91df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd5b4100-37a0-40f7-8bc9-902608791ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify\n",
    "x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bce02603-173b-4a49-91ad-bebfee069baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another example:\n",
    "# f(vector x) = x1 + x2 + ... + xn\n",
    "# Gradient should be [1, 1, ..., 1]\n",
    "\n",
    "# clear previous values\n",
    "x.grad.zero_()\n",
    "# define the f(x)\n",
    "y = x.sum()\n",
    "# find the derivatives\n",
    "y.backward()\n",
    "# check the grandients\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cc42585-c63c-4174-a418-0a8bc5ff93be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for non-scalars.\n",
    "# Using Jacobian matrix (internally).\n",
    "x = torch.arange(3.0, requires_grad=True)\n",
    "# define the f(x)\n",
    "y = x * x\n",
    "# find the derivatives\n",
    "y.backward(torch.tensor([1.0, 1.0, 1.0]))\n",
    "# check the grandients\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d146d7ad-0dad-4204-91a6-cca82fcba54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(3.0, requires_grad=True)\n",
    "y = x * x\n",
    "\n",
    "# notice the 3rd element in the input vector parameter\n",
    "y.backward(torch.tensor([1.0, 1.0, 0]))\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96053b21-25de-4d2b-a00e-ce911aad575d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36., 81.]) tensor([-12.,  -8.])\n"
     ]
    }
   ],
   "source": [
    "# Another example, now using tensors:\n",
    "# Say Q = 3aˆ3 - bˆ2; with a = [a1, a2].T and b = [b1, b2].T\n",
    "# The Jacobian matrix is\n",
    "#   J = [ 9a1ˆ2   -2b1   0      0   ]\n",
    "#       [ 0       0      9a2ˆ2  -2b2]\n",
    "#\n",
    "#  given v= [1 1]ˆT\n",
    "#\n",
    "#   JˆT . v = [9a1ˆ2   -2b1   9a2ˆ2   -2b2].T\n",
    "#\n",
    "# with pytorch:\n",
    "\n",
    "a = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "b = torch.tensor([6.0, 4.0], requires_grad=True)\n",
    "\n",
    "Q = 3 * a**3 - b**2\n",
    "\n",
    "external_grad = torch.tensor([1, 1])\n",
    "\n",
    "# notice the 3rd element in the input vector parameter\n",
    "Q.backward(gradient=external_grad)\n",
    "print(a.grad, b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e2426e-51aa-4c1d-8ab0-e30039eba82f",
   "metadata": {},
   "source": [
    "\n",
    "with $a = [2., 3.]$\n",
    "\n",
    "$\\nabla a = [9 a_1^2, 9 a_2^2] = [9*2^2, 9*3^2] = [36, 81]$\n",
    "\n",
    "with $b = [6., 4.]$\n",
    "\n",
    "$\\nabla b = [-2b_1, -2b_2] = [-2*6, -2*4] = [-12, -8]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34fa729-b3f6-4cff-ac4e-9541ef4cd495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
