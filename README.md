ml-laboratory
==============================

My playground for machine learning tests.

> Be aware that most of the code is not complete and might not work as expected.


Preparing the environment
-------------------------

Conda is the environment manager used to run this project. 

To install `miniconda` go to [this link](https://conda.io/en/master/miniconda.html)

Assuming the url is still valid, you can also run:

```bash
$ wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh -O ~/miniconda.sh
$ bash ~/miniconda.sh -p $HOME/miniconda

# Check if the path is correctly set. Otherwise, set it on the user profile
# export PATH="$HOME/miniconda/bin:$PATH"
```

To create the environment run the following command:

```bash
$ make create_env
```

> NOTE: specific data science packages used in this project are listed in the `environment.yml` file. 
> In case you are not using `conda` to manage the runtime environment, make sure you include the necessary 
> dependencies your python environment installation.


Executing the code
------------------

Check `Makefile` commands to create environment and run the code.

You can use `jupyter notebook` or `jupyter lab` commands to run the notebooks available in the project. 
Make sure you activate the correct environment first and the execute the notebook:

```bash
$ conda env list
base                  *  /usr/local/miniconda3
ml-laboratory            /usr/local/miniconda3/envs/ml-laboratory
$
$ conda activate ml-laboratory
$ cd path/to/the/project
$ jupyter lab
```

Project Organization
--------------------

    ├── LICENSE
    ├── Makefile
    ├── README.md
    ├── environment.yml
    ├── setup.py
    ├── mypy.ini
    ├── tox.ini                     <- tox file with settings for running tox; see tox.testrun.org
    ├── data
    │   ├── external                <- Data from third party sources.
    │   ├── generated               <- Data generated by scripts in this project.
    │   ├── interim                 <- Intermediate data that has been transformed.
    │   ├── processed               <- The final, canonical data sets for modeling.
    │   └── raw                     <- The original, immutable data dump.
    │
    ├── docs                        <- A default Sphinx project; see sphinx-doc.org for details
    │
    ├── models                      <- Trained and serialized models, model predictions, or model summaries
    │
    ├── notebooks                   <- Jupyter notebooks. Naming convention is a number (for ordering), and a short `-` delimited description.
    │   ├── cases
    │   └── tutorials
    │
    ├── references                  <- Data dictionaries, manuals, and all other explanatory materials.
    │
    ├── reports                     <- Generated analysis as HTML, PDF, LaTeX, etc.
    │   └── figures                 <- Generated graphics and figures to be used in reporting
    │
    └── src                         <- Source code for use in this project.
        ├── __init__.py             <- Makes src a Python module
        ├── data                    <- Scripts to download or generate data
        │   └── make_dataset.py
        │   
        ├── features                <- Scripts to turn raw data into features for modeling
        │   └── build_features.py
        ├── main                    <- Holds python code implementing other business logic.
        |   |                          Added to comply with PyBuilder structure.
        │   └── python
        ├── models                  <- Scripts to train models and then use trained models to make predictions
        │   ├── predict_model.py
        │   └── train_model.py
        └── visualization           <- Scripts to create exploratory and results oriented visualizations
    

--------



<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>



