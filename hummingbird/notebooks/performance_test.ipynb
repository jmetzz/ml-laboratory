{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import PurePath\n",
    "\n",
    "# add custom python modules root to the path variable,\n",
    "from typing import Dict\n",
    "root_path = PurePath(os.getcwd()).parents[2].joinpath('src')\n",
    "if root_path not in sys.path:\n",
    "    sys.path.insert(0, str(root_path))\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from typing import Tuple, Dict\n",
    "from sklearn import metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _oversampling(train_data: pd.DataFrame, config: Dict) -> pd.DataFrame:\n",
    "    counts = dict(train_data[config[\"dependent_var\"]].value_counts())\n",
    "\n",
    "    train_data_class_0 = train_data[train_data[config[\"dependent_var\"]] == 0]\n",
    "    train_data_class_1 = train_data[train_data[config[\"dependent_var\"]] == 1]\n",
    "\n",
    "    if counts[1] > counts[0]:\n",
    "        train_data_class_0_over = train_data_class_0.sample(counts[1], replace=True, random_state=0)\n",
    "        train_data_over = pd.concat([train_data_class_1, train_data_class_0_over], axis=0)\n",
    "    else:\n",
    "        train_data_class_1_over = train_data_class_1.sample(counts[0], replace=True, random_state=0)\n",
    "        train_data_over = pd.concat([train_data_class_0, train_data_class_1_over], axis=0)\n",
    "\n",
    "    return train_data_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data(data_for_modeling: pd.DataFrame, config: Dict)-> Tuple:\n",
    "    number_waves = sum(\n",
    "        data_for_modeling[[\"wave\"] + config[\"feature_vars\"]].groupby(\"wave\").sum().sum(axis=1) > 0\n",
    "    )\n",
    "\n",
    "    X = data_for_modeling[config[\"feature_vars\"]]\n",
    "    y = data_for_modeling[[config[\"dependent_var\"]]]\n",
    "\n",
    "    sss = StratifiedShuffleSplit(test_size=0.1, random_state=0)\n",
    "    sss_split_indices = next(sss.split(X, y))\n",
    "\n",
    "    train_data = data_for_modeling.iloc[sss_split_indices[0]]\n",
    "    train_data_oversampled = _oversampling(train_data, config)\n",
    "\n",
    "    X_training = train_data_oversampled[config[\"feature_vars\"]]\n",
    "    y_training = train_data_oversampled[config[\"dependent_var\"]]\n",
    "\n",
    "    validation_data = data_for_modeling.iloc[sss_split_indices[1]]\n",
    "    X_validation = validation_data[config[\"feature_vars\"]]\n",
    "    y_validation = validation_data[config[\"dependent_var\"]]\n",
    "\n",
    "    return (X_training, y_training), (X_validation, y_validation)\n",
    "\n",
    "\n",
    "def build_model(X_training, y_training, X_validatin, y_validation, config: Dict) -> pd.DataFrame:\n",
    "    weights = data_for_modeling[[\"_SYS_RESPONDENT_WEIGHT\"]]\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_training, y_training)\n",
    "    lgb_val = lgb.Dataset(X_validation, y_validation, reference=lgb_train)\n",
    "\n",
    "    model = lgb.train({\"boosting_type\": \"gbdt\", \"objective\": \"binary\", \"metric\": \"binary_logloss\"},\n",
    "                      lgb_train,\n",
    "                      valid_sets=[lgb_train, lgb_val],\n",
    "                      early_stopping_rounds=5,\n",
    "                      verbose_eval=True,\n",
    "                      \n",
    "                     )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# data_for_modeling = ...\n",
    "# data_for_modeling.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_training, y_training), (X_validation, y_validation) = prepare_data(data_for_modeling, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = build_model(X_training, y_training, X_validation, y_validation, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, weights, brand, expected_y, predicted_y):\n",
    "    auc = metrics.roc_auc_score(expected_y, predicted_y)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        explainer = shap.TreeExplainer(model, feature_perturbation=\"tree_path_dependent\")\n",
    "        shap_values_local = explainer.shap_values(X)[1]\n",
    "\n",
    "    shap_values_global = np.sum(\n",
    "        np.multiply(np.multiply(shap_values_local, X.replace(0, -1)), weights), axis=0\n",
    "    ) / np.sum(weights[\"_SYS_RESPONDENT_WEIGHT\"])\n",
    "\n",
    "    modeling_result = pd.DataFrame(shap_values_global, columns=[brand]).T\n",
    "\n",
    "    return modeling_result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = data_for_modeling[config[\"feature_vars\"]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%time predicted_y = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted_y = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weights = data_for_modeling[[\"_SYS_RESPONDENT_WEIGHT\"]]\n",
    "expected_y = data_for_modeling[config[\"dependent_var\"]]\n",
    "evaluate(model, weights, brand, expected_y, predicted_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = data_for_modeling[[\"_SYS_RESPONDENT_WEIGHT\"]]\n",
    "expected_y = data_for_modeling[config[\"dependent_var\"]]\n",
    "evaluate(model, weights, brand, expected_y, predicted_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, weights, brand, expected_y, predicted_y):\n",
    "    auc = metrics.roc_auc_score(expected_y, predicted_y)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        explainer = shap.TreeExplainer(model, feature_perturbation=\"tree_path_dependent\")\n",
    "        shap_values_local = explainer.shap_values(X)[1]\n",
    "\n",
    "    shap_values_global = np.sum(\n",
    "        np.multiply(np.multiply(shap_values_local, X.replace(0, -1)), weights), axis=0\n",
    "    ) / np.sum(weights[\"_SYS_RESPONDENT_WEIGHT\"])\n",
    "\n",
    "    modeling_result = pd.DataFrame(shap_values_global, columns=[brand]).T\n",
    "\n",
    "    return modeling_result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_for_modeling[config[\"feature_vars\"]]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "predicted_y = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = data_for_modeling[[\"_SYS_RESPONDENT_WEIGHT\"]]\n",
    "expected_y = data_for_modeling[config[\"dependent_var\"]]\n",
    "evaluate(model, weights, brand, expected_y, predicted_y)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
