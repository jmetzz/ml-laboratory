{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, Dense, GlobalAveragePooling2D, Dropout, Activation, MaxPooling2D, Flatten\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Data Augumentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "\n",
    "```python\n",
    "# Data augumentation example\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('resources/data/small-food-101/data/train/cheesecake/72295.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='resources/gen-data', \n",
    "                          save_prefix='cheesecake', \n",
    "                          save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_path=\"/Users/jean/workspaces/image-classification/resources/data\"\n",
    "base_path=\"../../../data/generated\"\n",
    "dataset_name = \"food-004-0.1\"\n",
    "\n",
    "train_path = f\"{base_path}/{dataset_name}/data/train\"\n",
    "test_path = f\"{base_path}/{dataset_name}/data/validation\"\n",
    "validation_path = f\"{base_path}/{dataset_name}/data/test\"\n",
    "\n",
    "batch_size = 16\n",
    "height = 150\n",
    "width = 150\n",
    "\n",
    "input_shape = (3, width, height) if K.image_data_format() == 'channels_first' else (width, height, 3)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rotation_range=40,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(height, width),\n",
    "        color_mode='rgb',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  # because categorical_crossentropy loss\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        validation_path,\n",
    "        target_size=(height, width),\n",
    "        color_mode='rgb',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(height, width),\n",
    "        color_mode='rgb',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plot_train_progress(keras.callbacks.Callback):\n",
    "    def __init__(self, plot_every_n_epochs = 5, plot_fraction = 0.9):\n",
    "        self.plot_frequency = plot_every_n_epochs\n",
    "        self.plot_fraction = plot_fraction #Plot only the most recent values\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(logs)\n",
    "        self.train_losses.append(logs.get('loss'))\n",
    "        self.train_acc.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "            \n",
    "        if epoch % self.plot_frequency == 0:\n",
    "            # You can chose the style of your preference\n",
    "            # print(plt.style.available) to see the available options\n",
    "            plt.style.use(\"seaborn\")\n",
    "            \n",
    "            nr_values_to_plot = int(self.plot_fraction * len(self.train_losses))\n",
    "            if nr_values_to_plot > 1:\n",
    "                t = list(range(nr_values_to_plot))\n",
    "                plt.plot(t, self.train_losses[-nr_values_to_plot:], label = \"train_loss\")\n",
    "                plt.plot(t, self.val_losses[-nr_values_to_plot:], label = \"val_loss\")\n",
    "                plt.plot(t, self.train_acc[-nr_values_to_plot:], label = \"train_acc\")\n",
    "                plt.plot(t, self.val_acc[-nr_values_to_plot:], label = \"val_acc\")            \n",
    "                plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(epoch))\n",
    "                plt.xlabel('# Batches')\n",
    "                plt.ylabel('Loss/Accuracy')\n",
    "                plt.legend()\n",
    "                #plt.savefig('train_progress.jpg')\n",
    "                plt.show()\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.train_losses.append(logs.get('loss'))\n",
    "        self.train_acc.append(logs.get('acc'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "\n",
    "# TODO:\n",
    "# TensorBoard callback\n",
    "# Email notification callback\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "callbacks_list = [checkpointer, plot_train_progress(5, .9), earlyStopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "n_channels = 3 # RGB\n",
    "\n",
    "\n",
    "# TODO: get from data generator\n",
    "n_classes = 4\n",
    "n_train_samples = 272\n",
    "n_validation_samples = 28\n",
    "n_test_samples = 100\n",
    "n_epochs=10\n",
    "optimizer='rmsprop'\n",
    "\n",
    "model_to_use='simple'\n",
    "\n",
    "if model_to_use == 'inception':\n",
    "    # Model definition\n",
    "    base_model = InceptionV3(\n",
    "        include_top=False, \n",
    "        weights='imagenet', \n",
    "        input_shape=(width, height, n_channels)) #input_tensor=None\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x) # or: pooling='avg'\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "   \n",
    "    # first: freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "elif model_to_use == 'custom-inception':\n",
    "    base_model = InceptionV3(\n",
    "        include_top=False, \n",
    "        weights='imagenet', \n",
    "        input_shape=(width, height, n_channels)) #input_tensor=None\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x) # or: pooling='avg'\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # train the top 2 inception blocks\n",
    "    for layer in model.layers[:249]:\n",
    "       layer.trainable = False\n",
    "    for layer in model.layers[249:]:\n",
    "       layer.trainable = True\n",
    "\n",
    "    optimizer=SGD(lr=0.0001, momentum=0.9)\n",
    "    checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5_tunning', verbose = 1, save_best_only=True)\n",
    "    callbacks_list = [checkpointer, plot_train_progress(5, .9), earlyStopping]\n",
    "else:\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=input_shape, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model.fit(x_train_color, y_train_color,\n",
    "#          batch_size=128,\n",
    "#          epochs=10,\n",
    "#          validation_data=(x_valid_color, y_valid_color),\n",
    "#          callbacks=callbacks_list)\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        epochs=n_epochs,\n",
    "        steps_per_epoch = n_train_samples // batch_size,\n",
    "        validation_data = validation_generator,\n",
    "        validation_steps = n_validation_samples // batch_size,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation - test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.weights.best.hdf5')\n",
    "test_score = model.evaluate_generator(test_generator, steps=100, workers=4)\n",
    "\n",
    "print(f\"Loss: {test_score[0]} ; Acc: {test_score[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = model.predict_generator(test_generator, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid rely on the dictionay keys order (e.g. dataset_labels = test_generator.class_indices.keys()),\n",
    "# first invert the class_indices dictionary and then generate the orderted list of labels\n",
    "#\n",
    "dataset_labels_inverted = {v: k for k, v in test_generator.class_indices.items()}\n",
    "dataset_labels = [dataset_labels_inverted[k] for k in sorted(dataset_labels_inverted.keys())]\n",
    "\n",
    "y_pred=test_prediction\n",
    "y_pred_integers = np.argmax(y_pred, axis = 1)\n",
    "y_pred_integers\n",
    "\n",
    "# TODO: get the true labels from dataset metadata\n",
    "import random\n",
    "true_labels = [random.randint(0, 3) for _ in range(100)] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility and visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_predictions(model, classes, test_set, y_test, y_hat, title_string):\n",
    "    # Plot a random sample of 10 test images, their predicted labels and ground truth\n",
    "    figure = plt.figure(figsize=(40, 40))\n",
    "    n_instances = test_set.shape[0]\n",
    "    for i, index in enumerate(np.random.choice(n_instances, size=n_instances, replace=False)):\n",
    "        ax = figure.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "        # Display each image\n",
    "        ax.imshow(np.squeeze(test_instances[index]), cmap = 'gray')\n",
    "        predict_index = np.argmax(y_hat[index])\n",
    "        true_index = np.argmax(y_test[index])\n",
    "        # Set the title for each image\n",
    "        ax.set_title(\"{} ({})\".format(classes[predict_index], \n",
    "                                      classes[true_index]),\n",
    "                                      color=(\"green\" if predict_index == true_index else \"red\"),\n",
    "                                      fontsize=45)\n",
    "    figure.suptitle(\"%s results:\" %title_string, fontsize=25)\n",
    "    \n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Building normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Building confusion matrix, without normalization')\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(true_labels, y_pred_integers)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=dataset_labels,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=dataset_labels, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize classification for a batch test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_set, y = test_generator.next()\n",
    "y_hat = model.predict(X).argmax(axis=-1)\n",
    "# y\n",
    "labels = [classes[c.argmax(axis=-1)] for c in y]\n",
    "predictions = [classes[c] for c in y_hat]\n",
    "\n",
    "print(\"Test set true labels:\")\n",
    "print(labels)\n",
    "\n",
    "print(\"\\n\\nTest set predictions:\")\n",
    "print(predictions)\n",
    "\n",
    "visualize_model_predictions(model, dataset_labels, test_set, y, y_hat, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
